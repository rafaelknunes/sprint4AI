{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predict Relief No Embedding**\n",
    "\n",
    "Nesta etapa queremos montar um modelo que, a partir de dados de entrada, prediz se uma reclamação irá incorrer no pagamento de indenização por parte da empresa financeira.\n",
    "\n",
    "Aqui, nossa variávl alvo é: `Company payed monetary relief` e assume o valor 1 quando a empresa fez o pagamento e 0 quando não fez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Importando Pickle da Base Tratada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 138)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('./pickle/df_processed.pkl')\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## **Separar Variáveis Desnecessárias**\n",
    "\n",
    "- Remover colunas desnecessárias ou que não podem ser usadas para a construção do modelo:\n",
    "    - `Complaint embedding`\n",
    "    - `Complaint ID`\n",
    "    - `Date received`\n",
    "    - `Sub-product`\n",
    "    - `Sub-issue`\n",
    "    - `Issue`\n",
    "    - `ZIP code`\n",
    "    - `Consumer complaint narrative`\n",
    "    - `Company response to consumer`\n",
    "    \n",
    "- Remover colunas que possuem poucas informações ou pouca variabilidade:\n",
    "    - `Tags`\n",
    "    - `State`\n",
    "\n",
    "- Remover colunas que indicam informações que só poderíamos ter após a reclamação ser resolvida:\n",
    "    - `Company response to consumer`\n",
    "    - `Consumer disputed?`\n",
    "    - `Suggested Category /Product / Reasoning`\n",
    "    - `Potential Annual Revenue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separando as colunas removidas em um DataFrame separado\n",
    "removed_columns = ['Complaint embedding', 'Complaint ID', 'Company', 'Date received',\n",
    "                   'Sub-product', 'Sub-issue', 'Issue', 'ZIP code',\n",
    "                   'Consumer complaint narrative', 'Company response to consumer']\n",
    "\n",
    "# Adicionando as colunas que começam com 'Tags', 'Company public response_Company', 'Consumer disputed?', 'Suggested'\n",
    "removed_columns += [col for col in df.columns if col.startswith('Tags')]\n",
    "removed_columns += [col for col in df.columns if col.startswith('Company public response_Company')]\n",
    "removed_columns += [col for col in df.columns if col.startswith('Consumer disputed?')]\n",
    "removed_columns += [col for col in df.columns if col.startswith('Suggested')]\n",
    "removed_columns += [col for col in df.columns if col.startswith('State')]\n",
    "\n",
    "# Adicionando 'Potential Annual Revenue'\n",
    "removed_columns.append('Potential Annual Revenue')\n",
    "\n",
    "# Criando o DataFrame com as colunas removidas\n",
    "df_removed = df[removed_columns].copy()\n",
    "\n",
    "# Removendo as colunas do DataFrame original\n",
    "df = df.drop(columns=removed_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Modelo de Previsão de Pagamento de Indenização**\n",
    "\n",
    "- Modelo: **Random Forest Classifier** é um modelo adquado quando a variável alvo é do tipo categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9077029840388618\n",
      "Matriz de Confusão:\n",
      " [[635  86]\n",
      " [ 47 673]]\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.88      0.91       721\n",
      "        True       0.89      0.93      0.91       720\n",
      "\n",
      "    accuracy                           0.91      1441\n",
      "   macro avg       0.91      0.91      0.91      1441\n",
      "weighted avg       0.91      0.91      0.91      1441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Definindo a variável alvo e as variáveis preditoras\n",
    "y = df['Company payed monetary relief']  # Variável alvo\n",
    "X = df.drop(columns=['Company payed monetary relief'])  # Variáveis preditoras\n",
    "\n",
    "# Preencher valores ausentes com a média das colunas\n",
    "#imputer = SimpleImputer(strategy='mean')\n",
    "#X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinando um modelo RandomForest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Reunindo as colunas removidas ao DataFrame original\n",
    "df_final = pd.concat([X_test, df_removed.loc[X_test.index]], axis=1)\n",
    "\n",
    "# Avaliação do modelo\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # **Resultados**\n",
    "\n",
    "|                  | Predicted: False | Predicted: True | Total Real Values |\n",
    "|------------------|------------------|-----------------|-------------------|\n",
    "| **Actual: False** | 636              | 85              | 721               |\n",
    "| **Actual: True**  | 50               | 670             | 720               |\n",
    "| **Total Predictions**  | 686              | 755              | 1441              |\n",
    "\n",
    "- True Negatives (TN): 636\n",
    "    - Estes são os casos em que o modelo previu False e a classe real também era False. O modelo acertou em prever que a empresa não pagou o alívio monetário.\n",
    "\n",
    "- False Positives (FP): 85\n",
    "    - Estes são os casos em que o modelo previu True, mas a classe real era False. Aqui, o modelo previu que a empresa pagaria o alívio monetário, mas, na realidade, não pagou. Este é um erro tipo I.\n",
    "\n",
    "- False Negatives (FN): 50\n",
    "    - Estes são os casos em que o modelo previu False, mas a classe real era True. Neste caso, o modelo previu que a empresa não pagaria o alívio monetário, mas, na realidade, pagou. Este é um erro tipo II.\n",
    "\n",
    "- True Positives (TP): 670\n",
    "    - Estes são os casos em que o modelo previu True e a classe real também era True. O modelo acertou em prever que a empresa pagou o alívio monetário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1441, 137)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# # **Exportando Modelo Treinado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributo encontrado\n"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'monotonic_cst'):\n",
    "    print(\"Atributo encontrado\")\n",
    "else:\n",
    "    print(\"Atributo não encontrado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/random_forest_predict_relief.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Salvar o modelo treinado\n",
    "joblib.dump(model, './model/random_forest_predict_relief.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Exportando Arquivos Gerados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_excel('./excel/df_predict_relief.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_pickle(\"./pickle/df_predict_relief.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook Predict Relief Concluído\n"
     ]
    }
   ],
   "source": [
    "print(\"Notebook Predict Relief Concluído\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_excel('./excel/X.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
